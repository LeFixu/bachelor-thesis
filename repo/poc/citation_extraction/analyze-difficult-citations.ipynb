{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440bcdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"citation module\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Quote:\n",
    "    \"\"\"Represents a citation / quote\"\"\"\n",
    "\n",
    "    position_in_text: Tuple[int, int]\n",
    "    citation: str\n",
    "    subject: str  # der Bundesrat Berset\n",
    "    citation_verb: str  # sagte, meinte, erklärte\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        position_in_text: int,\n",
    "        citation: str,\n",
    "        subject: str,\n",
    "        citation_verb: str,\n",
    "    ):\n",
    "        self.position_in_text = (\n",
    "            position_in_text + 1,\n",
    "            position_in_text + 1 + len(citation),\n",
    "        )\n",
    "        self.citation = citation\n",
    "        self.subject = subject\n",
    "        self.citation_verb = citation_verb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de217a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module can be used to extract citations from a string.\n",
    "Currently only syntactic quotes included\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from functools import reduce\n",
    "from operator import iconcat\n",
    "from typing import List, Optional, Callable, Tuple, TypeVar, Iterator\n",
    "from nltk import Tree  # type: ignore\n",
    "from spacy import load\n",
    "from spacy.tokens import Doc, Token\n",
    "from spacy.language import Language\n",
    "\n",
    "\n",
    "class _NotFoundError(BaseException):\n",
    "    pass\n",
    "\n",
    "\n",
    "__NLP: Optional[Language] = None  # cached spacy parser instance\n",
    "\n",
    "\n",
    "def __get_nlp(model: str = \"de_core_news_lg\") -> Language:\n",
    "    # pylint: disable=global-statement\n",
    "    global __NLP\n",
    "    # pylint: enable=global-statement\n",
    "    if __NLP is None:\n",
    "        __NLP = load(model)\n",
    "    return __NLP\n",
    "\n",
    "\n",
    "def __get_roots(string: str) -> Iterator[Token]:\n",
    "    return (sent.root for sent in __get_nlp()(string).sents)\n",
    "\n",
    "\n",
    "__QUOTATION_VERBS: Optional[List[str]] = None\n",
    "\n",
    "\n",
    "def __get_quotation_verbs() -> List[str]:\n",
    "    verbs = \"sagen meinen erzählen versichern erklären betonen mitteilen ankündigen begrüssen twittern zitieren teilen bringen berichten schreiben verraten bestätigen dementieren rufen aufrufen empfehlen stellen feststellen fassen zusammenfassen behaupten verweisen bezeichnen argumentieren kontern kündigen nennen rechnen erwidern fragen werfen\"\n",
    "    return verbs.split(\" \")\n",
    "\n",
    "\n",
    "def __get_hilfsverben() -> List[str]:\n",
    "    return [\"sein\", \"haben\"]\n",
    "\n",
    "\n",
    "# Breadth First Search\n",
    "def __get_nearest_tokens_by_condition(\n",
    "    node: Token, condition: Callable[[Token], bool]\n",
    ") -> List[Token]:\n",
    "    def get_nearest_by(\n",
    "        node: Token, condition: Callable[[Token], bool], depth: int\n",
    "    ) -> List[Tuple[Token, int]]:\n",
    "        # check current node\n",
    "        if condition(node):\n",
    "            return [(node, depth)]\n",
    "\n",
    "        # Recursion step (flatten result)\n",
    "        return __get_flattened_list(\n",
    "            [get_nearest_by(n, condition, depth + 1) for n in node.children]\n",
    "        )\n",
    "\n",
    "    results = get_nearest_by(node, condition, 0)\n",
    "    if len(results) < 1:\n",
    "        return []\n",
    "    min_depth = min(results, key=lambda t: t[1])[1]\n",
    "\n",
    "    return list(map(lambda t: t[0], filter(lambda t: t[1] == min_depth, results)))\n",
    "\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def __get_flattened_list(list_of_lists: List[List[T]]) -> List[T]:\n",
    "    return reduce(iconcat, list_of_lists, [])\n",
    "\n",
    "\n",
    "def __get_flattened_tree(node: Token) -> List[Token]:\n",
    "    def get_flattened_tree_(node: Token) -> List[Token]:\n",
    "        return reduce(\n",
    "            iconcat, [get_flattened_tree_(child) for child in node.children], [node]\n",
    "        )\n",
    "\n",
    "    return sorted(get_flattened_tree_(node), key=lambda x: x.i)\n",
    "\n",
    "\n",
    "def __get_text_from_tree(node: Token) -> str:\n",
    "    return \"\".join(map(lambda x: x.text_with_ws, __get_flattened_tree(node))).strip()\n",
    "\n",
    "\n",
    "def __get_subject_node(node: Token) -> Token:\n",
    "    condition = lambda n: n.dep_ == \"sb\"\n",
    "    result = __get_nearest_tokens_by_condition(node, condition)\n",
    "    if len(result) < 1:\n",
    "        raise _NotFoundError()\n",
    "    return result[0]\n",
    "\n",
    "\n",
    "def __get_quote_node(root: Token) -> Token:\n",
    "    result = []\n",
    "\n",
    "    # Perfekt, Plusquamperfekt, Futur\n",
    "    if root.lemma_ in __get_hilfsverben():\n",
    "        print(\"Perfekt, Plusquamperfekt, Futur\")\n",
    "        condition = (\n",
    "            lambda n: n.head.lemma_ in __get_quotation_verbs() and n.dep_ == \"oc\"\n",
    "        )\n",
    "        result = __get_flattened_list(\n",
    "            [__get_nearest_tokens_by_condition(c, condition) for c in root.children]\n",
    "        )\n",
    "\n",
    "    # Präsens, Präteritum\n",
    "    if root.lemma_ in __get_quotation_verbs():\n",
    "        print(\"räsens, Präteritum\")\n",
    "        result = [x for x in root.children if x.dep_ == \"oc\"]\n",
    "\n",
    "    if len(result) < 1:\n",
    "        raise _NotFoundError()\n",
    "\n",
    "    print(result[0])\n",
    "    return result[0]\n",
    "\n",
    "\n",
    "def __get_subject(node: Token) -> str:\n",
    "    return __get_text_from_tree(__get_subject_node(node))\n",
    "\n",
    "\n",
    "def __get_quote(node: Token) -> str:\n",
    "    return __get_text_from_tree(__get_quote_node(node))\n",
    "\n",
    "\n",
    "def __get_syntactic_quote(node: Token) -> Optional[Quote]:\n",
    "    try:\n",
    "        position_in_text = node.idx\n",
    "        subject = __get_subject(node)\n",
    "        citation = __get_quote(node)\n",
    "        citation_verb = __get_quote_node(node).head.text\n",
    "\n",
    "        return Quote(\n",
    "            position_in_text,\n",
    "            citation,\n",
    "            subject,\n",
    "            citation_verb,\n",
    "        )\n",
    "    except _NotFoundError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def print_nltk_tree(text: str) -> None:\n",
    "    \"\"\"Print a nltk parse tree for the given text\"\"\"\n",
    "\n",
    "    def tok_format(tok: Token) -> str:\n",
    "        return \"_\".join([tok.orth_, tok.dep_])\n",
    "\n",
    "    def to_nltk_tree_(node: Token) -> Tree:\n",
    "        if node.n_lefts + node.n_rights > 0:\n",
    "            return Tree(\n",
    "                tok_format(node), [to_nltk_tree_(child) for child in node.children]\n",
    "            )\n",
    "        return tok_format(node)\n",
    "\n",
    "    doc = __get_nlp()(text)\n",
    "    _ = [to_nltk_tree_(sent.root).pretty_print() for sent in doc.sents]\n",
    "\n",
    "\n",
    "def get_syntactic_quotes(string: str) -> List[Quote]:\n",
    "    \"\"\"Get all syntactic quotes from a given string\"\"\"\n",
    "    roots = __get_roots(string)\n",
    "    quotes = map(__get_syntactic_quote, roots)\n",
    "    return list(filter(lambda x: x is not None, quotes))  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef1ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "from spacy.tokens.token import Token\n",
    "from typing import Callable, Optional\n",
    "from spacy.lang.de.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "doc = nlp(sentences[0])\n",
    "\n",
    "def to_nltk_tree(sentence: str, tok_format: Optional[Callable[Token, str]] = None):\n",
    "    def tok_format_(tok: Token):\n",
    "        return \"_\".join([tok.orth_, tok.dep_])\n",
    "    \n",
    "    if tok_format is None:\n",
    "        tok_format = tok_format_\n",
    "        \n",
    "    def to_nltk_tree_(node: Token):\n",
    "        if node.n_lefts + node.n_rights > 0:\n",
    "            return Tree(tok_format(node), [to_nltk_tree_(child) for child in node.children])\n",
    "        else:\n",
    "            return tok_format(node)\n",
    "        \n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    ret_val = []\n",
    "    for sent in doc.sents:\n",
    "        nltk_tree = to_nltk_tree_(sent.root)\n",
    "        if isinstance(nltk_tree,str):\n",
    "            ret_val.append(nltk_tree)\n",
    "        else:\n",
    "            ret_val.append(nltk_tree.pretty_print())\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c17125",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Dort habe er in einer Wohnung auch einen Grossteil seiner Sachen, unter anderem Familienerbstücke, wie das Inventar aus dem Restaurant Rossberg, wie der «Landbote» schreibt.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba69fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            habe_ROOT                                                                                                          \n",
      "    ____________________________________________________________________________|__________________                                                                                             \n",
      "   |      |      |        |                                                                   Grossteil_oa                                                                                     \n",
      "   |      |      |        |          ______________________________________________________________|_____________________                                                                       \n",
      "   |      |      |        |         |       |        |        |                                                   Familienerbstück                                                             \n",
      "   |      |      |        |         |       |        |        |                                                        e_par                                                                   \n",
      "   |      |      |        |         |       |        |        |         _________________________________________________|___________________________                                           \n",
      "   |      |      |        |         |       |        |        |        |        |                                                               schreibt_mnr                                   \n",
      "   |      |      |        |         |       |        |        |        |        |         ___________________________________________________________|___________________________               \n",
      "   |      |      |        |         |       |        |        |        |        |        |         |                               Inventar_sb                                   |             \n",
      "   |      |      |        |         |       |        |        |        |        |        |         |          __________________________|____________                            |              \n",
      "   |      |      |      in_mo       |       |        |        |        |        |        |         |         |                                    aus_mnr                        |             \n",
      "   |      |      |        |         |       |        |        |        |        |        |         |         |                                       |                           |              \n",
      "   |      |      |    Wohnung_nk    |       |        |    Sachen_ag    |     unter_mo    |         |         |                                 Restaurant_nk                Landbote_sb        \n",
      "   |      |      |        |         |       |        |        |        |        |        |         |         |            ___________________________|__________        _________|_________     \n",
      "Dort_mo er_sb ._punct  einer_nk  auch_mo einen_nk ,_punct seiner_nk ,_punct anderem_nk wie_mo    wie_mo    das_nk      dem_nk                   Rossberg_nk  ,_punct der_nk   «_punct   »_punct\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_nltk_tree(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1369a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfekt, Plusquamperfekt, Futur\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_syntactic_quotes(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2970a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = \"\"\"\n",
    "Der Bundesrat schafft ein neues Staatssekretariat für Sicherheit im Verteidigungsdepartement (VBS). Es erarbeitet und koordiniert ab dem 1. Januar 2024 eine gesamtheitliche Sicherheitspolitik. Das Cybersicherheits-Zentrum wechselt vom Finanzdepartement ins VBS.\n",
    "Das Departement für Verteidigung, Bevölkerungsschutz und Sport (VBS) wird bis Ende Jahr die rechtlichen Grundlagen erarbeiten, wie der Bundesrat am Mittwoch mitteilte. Anstoss zu dem neuen Staatssekretariat gab der Krieg in der Ukraine.\n",
    "\"\"\"\n",
    "\n",
    "get_syntactic_quotes(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d27360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                wird_ROOT                                                                            \n",
      "    ________________________________________________________________________________|________________________________________                                         \n",
      "   |                                    Departement_sb                                                                       |                                       \n",
      "   |       ___________________________________|____________________                                                          |                                        \n",
      "   |      |                für_mnr                                 |                                                         |                                       \n",
      "   |      |                   |                                    |                                                         |                                        \n",
      "   |      |            Verteidigung_nk                             |                                                   erarbeiten_oc                                 \n",
      "   |      |        ___________|_______________                     |                 ________________________________________|____________________                    \n",
      "   |      |       |                    Bevölkerungsschu            |                |      bis_mo              |                             mitteilte_mo            \n",
      "   |      |       |                         tz_cj                  |                |        |                 |                                  |                  \n",
      "   |      |       |                           |                    |                |        |                 |                         _________|____________       \n",
      "   |      |       |                         und_cd              VBS_app             |     Ende_nk        Grundlagen_oa                  |    Bundesrat_sb    am_mo   \n",
      "   |      |       |                           |             _______|_______         |        |       __________|_____________           |         |            |      \n",
      "._punct Das_nk ,_punct                     Sport_cj     (_punct         )_punct  ,_punct  Jahr_nk die_nk               rechtlichen_nk wie_mo    der_nk    Mittwoch_nk\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Das Departement für Verteidigung, Bevölkerungsschutz und Sport (VBS) wird bis Ende Jahr die rechtlichen Grundlagen erarbeiten, wie der Bundesrat am Mittwoch mitteilte.\"\n",
    "get_syntactic_quotes(sentence)\n",
    "to_nltk_tree(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f045b3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
